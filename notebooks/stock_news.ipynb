import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from transformers import pipeline

from google.colab import files
uploaded = files.upload()


df = pd.read_csv('raw_analyst_ratings.csv')

print(df.columns)

df['headline_length'] = df['headline'].apply(len)

print(df['headline_length'].describe())
articles_per_publisher = df['publisher'].value_counts()

print(articles_per_publisher)

 df['date'] = pd.to_datetime(df['date'])

articles_per_publisher = df['publisher'].value_counts()

# Plot the number of articles per publisher
articles_per_publisher.plot(kind='bar', figsize=(10, 3))
plt.title('Number of Articles per Publisher')
plt.xlabel('Publisher')
plt.ylabel('Number of Articles')
plt.show()

print(df['date'].dtype)

df['date'] = pd.to_datetime(df['date'], errors='coerce')

df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d', errors='coerce')

print(df['date'].dtype)   
print(df['date'].head())

print(df['date'].dtype)  
print(df['date'].head())

plt.figure(figsize=(10, 6))
sns.barplot(x=articles_per_day.index, y=articles_per_day.values, palette="viridis")
plt.title('Number of Articles Published per Day of the Week')
plt.xlabel('Day of the Week')
plt.ylabel('Number of Articles')
plt.show()



import matplotlib.pyplot as plt  
import seaborn as sns 

plt.figure(figsize=(10, 6))
sns.barplot(x=articles_per_day.index, y=articles_per_day.values, palette="viridis")
plt.title('Number of Articles Published per Day of the Week')
plt.xlabel('Day of the Week')
plt.ylabel('Number of Articles')
plt.show()



from textblob import TextBlob
def analyze_sentiment(text):
    analysis = TextBlob(text)
    return analysis.sentiment.polarity

# Apply sentiment analysis to each headline
df['sentiment_polarity'] = df['headline'].apply(analyze_sentiment)

# Categorize sentiment
df['sentiment'] = df['sentiment_polarity'].apply(
    lambda x: 'Positive' if x > 0 else ('Negative' if x < 0 else 'Neutral')
)

# View the results
print(df[['headline', 'sentiment']].head())


!pip install gensim nltk
import pandas as pd
from gensim import corpora, models
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
nltk.download('punkt')
nltk.download('stopwords')


stop_words = set(stopwords.words('english'))

def preprocess(text):
    tokens = word_tokenize(text.lower())
    tokens = [word for word in tokens if word.isalpha()]
    tokens = [word for word in tokens if word not in stop_words]
    return tokens

df['tokens'] = df['headline'].apply(preprocess)


dictionary = corpora.Dictionary(df['tokens'])
corpus = [dictionary.doc2bow(text) for text in df['tokens']]



lda_model = models.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)

topics = lda_model.print_topics(num_words=4)
for topic in topics:
    print(topic)

    import pyLDAvis
import pyLDAvis.gensim_models as gensimvis
import gensim

# Visualize the topics
vis = gensimvis.prepare(lda_model, corpus, dictionary)
pyLDAvis.display(vis)



import matplotlib.pyplot as plt

# Count the number of articles published each day
daily_counts = df['date'].value_counts().sort_index()

# Plot the daily publication frequency
plt.figure(figsize=(12, 6))
daily_counts.plot(kind='line', color='blue')
plt.title('Daily Publication Frequency')
plt.xlabel('Date')
plt.ylabel('Number of Articles')
plt.xticks(rotation=45)
plt.show()

df['month_year'] = df['date'].dt.to_period('M')

# Count the number of articles published each month
monthly_counts = df['month_year'].value_counts().sort_index()

# Plot the monthly publication frequency
plt.figure(figsize=(12, 6))
monthly_counts.plot(kind='line', color='green')
plt.title('Monthly Publication Frequency')
plt.xlabel('Month-Year')
plt.ylabel('Number of Articles')
plt.xticks(rotation=45)
plt.show()

event_period_df = df[(df['date'] >= '2020-01-01') & (df['date'] <= '2020-11-25')]

# Count the number of articles published per day during the event
event_daily_counts = event_period_df['date'].value_counts().sort_index()

# Plot the publication frequency during the event
plt.figure(figsize=(12, 6))
event_daily_counts.plot(kind='line', color='red')
plt.title('Publication Frequency During January 2020 up to November 2020')
plt.xlabel('Date')
plt.ylabel('Number of Articles')
plt.xticks(rotation=45)
plt.show()


plt.figure(figsize=(12, 6))
daily_counts.plot(kind='line', color='blue')
plt.axvline(pd.to_datetime('2023-01-15'), color='red', linestyle='--', label='Market Event')
plt.title('Daily Publication Frequency with Market Event Highlight')
plt.xlabel('Date')
plt.ylabel('Number of Articles')
plt.xticks(rotation=45)
plt.legend()
plt.show()

hourly_counts = df['hour'].value_counts().sort_index()

 













